{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "impaired-treasury",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path as op\n",
    "import pickle as pkl\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "italic-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1010)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-graphic",
   "metadata": {},
   "source": [
    "# MNIST-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "plain-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_targets(base_dir, funs):\n",
    "    r = {\n",
    "        \"path\": [op.join(base_dir, b) \n",
    "     for b in [a for a in os.walk(base_dir)][0][2]]\n",
    "    }\n",
    "    r[\"original_label\"] = [\n",
    "        int(op.splitext(op.split(a)[-1])[0].split(\"_\")[1]) \n",
    "                           for a in r[\"path\"]\n",
    "    ]\n",
    "    df = pd.DataFrame(r)\n",
    "    for a in funs:\n",
    "        df[a[0]] = df[\"original_label\"].apply(a[1])\n",
    "    return(df)\n",
    "\n",
    "def relabel(n=0, inliers=True, supervised=True, n_classes=10):\n",
    "    if supervised:\n",
    "        w = (0, 1) if inliers else (1, 0)\n",
    "        return(\n",
    "            lambda x: w[1] if x == n else w[0]\n",
    "        )\n",
    "    else:\n",
    "        arrangement = np.arange(n_classes)\n",
    "        substitute = {\n",
    "            a: -1 if a == n else a-1 if a > n else a for a in arrangement\n",
    "        }\n",
    "        return(\n",
    "            lambda x: substitute[x]\n",
    "        )\n",
    "\n",
    "def disbalance_data(labels, percentage):\n",
    "    normal_indices = np.arange(labels.shape[0])[labels == 0]\n",
    "    anomal_indices = np.arange(labels.shape[0])[labels == 1]\n",
    "    what_to_take = int(np.round(normal_indices.shape[0]/(100-percentage)*percentage))\n",
    "    if what_to_take < anomal_indices.shape[0]:\n",
    "        _, fraction, _, _ = train_test_split(\n",
    "            anomal_indices, labels[labels == 1], test_size=what_to_take\n",
    "        )\n",
    "    else:\n",
    "        fraction = anomal_indices\n",
    "    return(np.concatenate([normal_indices, fraction]))\n",
    "\n",
    "def train_test(df, percentages):\n",
    "    r = {}\n",
    "    for p in percentages:\n",
    "        for a in tqdm(df.columns[2:]):\n",
    "            if -1 not in df[a].values:\n",
    "                r[a+\"_\"+str(p)] = disbalance_data(\n",
    "                    df[a].values, p\n",
    "                )\n",
    "            else:\n",
    "                r[a] = np.arange(df.shape[0])[df[a].values != -1]\n",
    "    return(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "social-efficiency",
   "metadata": {},
   "outputs": [],
   "source": [
    "di_funs = [(\"SDI_\"+str(a), relabel(a)) for a in np.arange(10)]\n",
    "do_funs = [(\"SDO_\"+str(a), relabel(a, False)) for a in np.arange(10)]\n",
    "udi_funs = [(\"UDI_\"+str(a), relabel(a, False, False)) for a in np.arange(10)]\n",
    "udo_funs = [(\"UDO\", lambda x: x) for a in np.arange(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "impressed-reaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "trains = [\n",
    "    \"../data/CIFAR10_train\",\n",
    "    \"../data/FMNIST_train\",\n",
    "    \"../data/KMNIST_train\",\n",
    "    \"../data/MNIST_train\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "quality-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = [\n",
    "    \"../data/CIFAR10_test\",\n",
    "    \"../data/FMNIST_test\",\n",
    "    \"../data/KMNIST_test\",\n",
    "    \"../data/MNIST_test\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "functional-television",
   "metadata": {},
   "outputs": [],
   "source": [
    "trains_dfs = [\n",
    "    prepare_targets(\n",
    "        a, di_funs+do_funs+udi_funs+udo_funs\n",
    "    ) for a in trains\n",
    "]\n",
    "tests_dfs = [\n",
    "    prepare_targets(\n",
    "        a, di_funs+do_funs+udi_funs+udo_funs\n",
    "    ) for a in tests\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ready-soviet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/CIFAR10_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:00<00:00, 1502.76it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 1330.57it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 1342.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/FMNIST_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:00<00:00, 1229.38it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 1190.57it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 1198.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/KMNIST_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:00<00:00, 1133.80it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 1106.38it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 1190.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/MNIST_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:00<00:00, 1376.26it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 1105.26it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 1173.13it/s]\n"
     ]
    }
   ],
   "source": [
    "for a,b in list(zip(trains, trains_dfs)):\n",
    "    print(a)\n",
    "    b.to_csv(a+\".csv\")\n",
    "    with open(a+\".pkl\", \"wb\") as oh:\n",
    "        tt = train_test(b, [10, 1, 0.1])\n",
    "        pkl.dump(tt, oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "political-blood",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 28.28it/s]\n"
     ]
    }
   ],
   "source": [
    "for a,b in tqdm(list(zip(tests, tests_dfs))):\n",
    "    b.to_csv(a+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "geographic-airport",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['path', 'original_label', 'SDI_0', 'SDI_1', 'SDI_2', 'SDI_3', 'SDI_4',\n",
       "       'SDI_5', 'SDI_6', 'SDI_7', 'SDI_8', 'SDI_9', 'SDO_0', 'SDO_1', 'SDO_2',\n",
       "       'SDO_3', 'SDO_4', 'SDO_5', 'SDO_6', 'SDO_7', 'SDO_8', 'SDO_9', 'UDI_0',\n",
       "       'UDI_1', 'UDI_2', 'UDI_3', 'UDI_4', 'UDI_5', 'UDI_6', 'UDI_7', 'UDI_8',\n",
       "       'UDI_9', 'UDO'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-swiss",
   "metadata": {},
   "source": [
    "# Peng et al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "popular-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "PENGPATH = \"../raw/PENG/bty558-suppl_data/Supplementary file 1.xlsx\"\n",
    "low = pd.read_excel(PENGPATH, sheet_name=0, engine=\"openpyxl\")\n",
    "high = pd.read_excel(PENGPATH, sheet_name=1, engine=\"openpyxl\")\n",
    "neg = pd.read_excel(PENGPATH, sheet_name=2, engine=\"openpyxl\")\n",
    "low_strs = [a+\",\"+b for a,b in zip(low[\"on-target site\"], low[\"off-target site\"])]\n",
    "high_strs = [a+\",\"+b for a,b in zip(high[\"on-target site\"], high[\"off-target site\"])]\n",
    "neg_strs = [a+\",\"+b for a,b in zip(neg[\"on-target site\"], neg[\"no editing site\"])]\n",
    "low_high = list(set(low_strs+high_strs))\n",
    "final_neg = neg_strs\n",
    "pairs = np.array(low_high+final_neg)\n",
    "labels = np.array([1]*len(low_high)+[0]*len(final_neg))\n",
    "N_MISMATCHES = 6\n",
    "n_mms = lambda x,y: np.sum([int(a != b) for a,b in zip(x,y)])\n",
    "worthy = np.array([n_mms(*a.split(\",\")) for a in pairs]) < N_MISMATCHES\n",
    "pairs = pairs[worthy]\n",
    "labels = labels[worthy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "known-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "PENG = pd.DataFrame(\n",
    "    {\n",
    "        \"path\": pairs, \"original_label\": labels\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "violent-melbourne",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "southwest-cambodia",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ix, test_ix = train_test_split(\n",
    "    np.arange(PENG.shape[0]), stratify=PENG[\"original_label\"].values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "varying-hammer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>original_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GGGTGGGGGGAGTTTGCTCCAGG,GGGAGGGTGGAGTTTGCTCCTGG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GTCACCTCCAATGACTAGGGTGG,GTCACTTCCAAGGACTAGAGAAG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GAACACAAAGCATAGACTGCGGG,GAATTCAAAGCATAGATTGCAGG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GACCCCCTCCACCCCGCCTCCGG,GTCCCCTCCCACCCCGCCTCCAG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GGCACTGCGGCTGGAGGTGGGGG,AGCACGGCAGCTGGAGGAGGGGG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26648</th>\n",
       "      <td>TGGATGGAGGAATGAGGAGTTGG,TTTATGGAGGAATGAGGAGATGG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26649</th>\n",
       "      <td>TGGATGGAGGAATGAGGAGTTGG,TTTATGGAGGATTGAGAAGATGG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26650</th>\n",
       "      <td>TGGATGGAGGAATGAGGAGTTGG,TTTATGGAGGGATAAGGAGTGGG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26651</th>\n",
       "      <td>TGGATGGAGGAATGAGGAGTTGG,TTTATTGATGACTGAGGAGTTGG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26652</th>\n",
       "      <td>TGGATGGAGGAATGAGGAGTTGG,TTTCTGGAGGAATGAAGATTTGG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26653 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  path  original_label\n",
       "0      GGGTGGGGGGAGTTTGCTCCAGG,GGGAGGGTGGAGTTTGCTCCTGG               1\n",
       "1      GTCACCTCCAATGACTAGGGTGG,GTCACTTCCAAGGACTAGAGAAG               1\n",
       "2      GAACACAAAGCATAGACTGCGGG,GAATTCAAAGCATAGATTGCAGG               1\n",
       "3      GACCCCCTCCACCCCGCCTCCGG,GTCCCCTCCCACCCCGCCTCCAG               1\n",
       "4      GGCACTGCGGCTGGAGGTGGGGG,AGCACGGCAGCTGGAGGAGGGGG               1\n",
       "...                                                ...             ...\n",
       "26648  TGGATGGAGGAATGAGGAGTTGG,TTTATGGAGGAATGAGGAGATGG               0\n",
       "26649  TGGATGGAGGAATGAGGAGTTGG,TTTATGGAGGATTGAGAAGATGG               0\n",
       "26650  TGGATGGAGGAATGAGGAGTTGG,TTTATGGAGGGATAAGGAGTGGG               0\n",
       "26651  TGGATGGAGGAATGAGGAGTTGG,TTTATTGATGACTGAGGAGTTGG               0\n",
       "26652  TGGATGGAGGAATGAGGAGTTGG,TTTCTGGAGGAATGAAGATTTGG               0\n",
       "\n",
       "[26653 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PENG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "recovered-oxide",
   "metadata": {},
   "outputs": [],
   "source": [
    "PENG_train = PENG.iloc[train_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aboriginal-monster",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-ff457074313d>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  PENG_train[\"random_label\"] = PENG_train[\"original_label\"].apply(\n"
     ]
    }
   ],
   "source": [
    "PENG_train[\"random_label\"] = PENG_train[\"original_label\"].apply(\n",
    "    lambda x: np.random.choice([0,1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "satellite-clone",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-be21ba67b57d>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  PENG_test[\"random_label\"] = PENG_test[\"original_label\"]\n"
     ]
    }
   ],
   "source": [
    "PENG_test = PENG.iloc[test_ix]\n",
    "PENG_test[\"random_label\"] = PENG_test[\"original_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "wrapped-frank",
   "metadata": {},
   "outputs": [],
   "source": [
    "PENG_train.to_csv(\"../data/PENG_train.csv\")\n",
    "PENG_test.to_csv(\"../data/PENG_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-designation",
   "metadata": {},
   "source": [
    "# HAM10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "incorporate-looking",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../raw/HAM10000.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "continuous-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(df[\"dx\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "closed-morocco",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bkl', 'nv', 'df', 'mel', 'vasc', 'bcc', 'akiec']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "hearing-lexington",
   "metadata": {},
   "outputs": [],
   "source": [
    "malignant = [\"mel\", \"bcc\", \"akiec\"]\n",
    "benign = [\"nv\", \"df\", \"vasc\", \"bkl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "emotional-hebrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not op.exists(\"../data/HAM10000\"):\n",
    "    os.makedirs(\"../data/HAM10000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "guided-samuel",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10015it [00:25, 386.44it/s]\n"
     ]
    }
   ],
   "source": [
    "newpath = []\n",
    "for a,b,i in tqdm(zip(df[\"path\"].values, df[\"dx\"].values, np.arange(df.shape[0]))):\n",
    "    npp = op.join(\"../data/HAM10000/\", str(i)+\"_\"+str(labels.index(b))+\".jpg\")\n",
    "    os.system(\n",
    "        \"cp \"+a+\" \"+npp\n",
    "    )\n",
    "    newpath.append(npp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "instructional-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"path\"] = newpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bigger-judges",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_lesions = df[\"lesion_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "direct-mercy",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ix, test_ix = train_test_split(np.arange(unique_lesions.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "elder-mattress",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lesions = unique_lesions[train_ix]\n",
    "test_lesions = unique_lesions[test_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "white-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lesions_b = df[\"lesion_id\"].apply(lambda x: x in train_lesions).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "unlimited-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"original_label\"] = df[\"dx\"].apply(lambda x: labels.index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "devoted-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"malignant\"] = df[\"dx\"].apply(lambda x: 1 if x in malignant else 0)\n",
    "df[\"benign\"] = df[\"dx\"].apply(lambda x: 1 if x in benign else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "particular-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"A\"] = df[\"malignant\"]\n",
    "df[\"B\"] = df[\"dx\"].apply(lambda x: 1 if x == \"mel\" else 0 if x in benign else -1)\n",
    "df[\"C\"] = df[\"dx\"].apply(lambda x: 1 if x in malignant else 0 if x == \"nv\" else -1)\n",
    "df[\"D\"] = df[\"dx\"].apply(lambda x: 1 if x == \"mel\" else 0 if x == \"nv\" else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "documented-compound",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.loc[train_lesions_b]\n",
    "train_df.to_csv(\"../data/HAM10000_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "polished-issue",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df.loc[np.logical_not(train_lesions_b)]\n",
    "test_df.to_csv(\"../data/HAM10000_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "changed-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = {\n",
    "    \"A\": np.arange(train_df.shape[0]),\n",
    "    \"B\": np.arange(train_df.shape[0]),\n",
    "    \"C\": np.arange(train_df.shape[0])[train_df[\"C\"].values != -1],\n",
    "    \"D\": np.arange(train_df.shape[0])[train_df[\"D\"].values != -1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "crazy-choir",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': array([   0,    1,    2, ..., 7502, 7503, 7504]),\n",
       " 'B': array([   0,    1,    2, ..., 7502, 7503, 7504]),\n",
       " 'C': array([  43,  873,  874, ..., 7502, 7503, 7504]),\n",
       " 'D': array([  43,  873,  874, ..., 7252, 7253, 7504])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "proud-challenge",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/HAM10000_train.pkl\", \"wb\") as oh:\n",
    "    pkl.dump(train_indices, oh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
